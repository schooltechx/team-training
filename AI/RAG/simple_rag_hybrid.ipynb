{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b2dac4",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# RAG Thai\n",
    "ใช้ ChatGPT ช่วยสร้างโค้ดบางส่วนยังไม่แน่ใจว่ามันทำงานถูกหรือเปล่า\n",
    "- Thai: ลองเพิ่มการจัดการภาษาไทย normalize tokenize split chunk\n",
    "- embeding : ใช้แบบ Opensource เช่น intfloat/multilingual-e5-base\n",
    "- Vector : FAISS สำหรับ Symantic Search\n",
    "- Full text : [rank_bm25](https://pypi.org/project/rank-bm25/) สำหรับ Full Text Search ตัวนี้ไม่รองรับการจัดการ text เราต้องทำเอง(ตัดคำ ตัดประโยค normalize)\n",
    "- Generate : ใช้ Gemini \n",
    "\n",
    "ให้ผลแม่นยำกว่า [simple_rag.ipynb](./simple_rag.ipynb) ทดสอบจากการค้นร้านอาหาร"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "134d87e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m162 packages\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m158 packages\u001b[0m \u001b[2min 0.07ms\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!uv add numpy google-genai pythainlp sentence-transformers faiss-cpu rank-bm25 ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "954c389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from google import genai\n",
    "from pythainlp import word_tokenize\n",
    "from pythainlp.util import normalize\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "\n",
    "if not os.environ.get(\"GEMINI_API_KEY\"):\n",
    "    raise ValueError(\"Please set the GEMINI_API_KEY environment variable\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "client = genai.Client()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa9a733",
   "metadata": {},
   "source": [
    "## Text utils\n",
    "ฟังก์ชั่นสำหรับจัดการข้อความ normalize, token, split, chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "41dd542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def th_normalize(text: str) -> str:\n",
    "    # ลบซ้ำวรรณยุกต์/สระยาว, normalize รูปแบบ, ตัดช่องว่างเกิน\n",
    "    t = normalize(text or \"\")\n",
    "    t = re.sub(r\"[^\\S\\r\\n]+\", \" \", t).strip()\n",
    "    # ลดเสียงลากยาว \"มากกกก\" -> \"มาก\"\n",
    "    t = re.sub(r\"(.)\\1{2,}\", r\"\\1\", t)\n",
    "    return t\n",
    "\n",
    "def th_tokenize(text: str):\n",
    "    # เลือก engine 'newmm' ซึ่งแม่นยำดีสำหรับไทย\n",
    "    return word_tokenize(text, engine=\"newmm\")\n",
    "\n",
    "def sent_split_th(text: str):\n",
    "    # แยกเป็นประโยคแบบง่าย ๆ ตามเครื่องหมายวรรคตอนไทย/อังกฤษ\n",
    "    # (สำหรับงานจริง อาจใช้ประโยคจาก Markdown heading/ย่อหน้าร่วมด้วย)\n",
    "    return re.split(r\"(?<=[\\.\\?\\!]|[ๆฯ])\\s+\", text.strip())\n",
    "\n",
    "# -------- Chunking ตามประโยค + ขนาดโทเคนคร่าว ๆ --------\n",
    "def chunk_by_sentences(text, max_chars=600, overlap_chars=80):\n",
    "    sents = [s for s in sent_split_th(th_normalize(text)) if s]\n",
    "    chunks = []\n",
    "    buf = \"\"\n",
    "    for s in sents:\n",
    "        if len(buf) + len(s) + 1 <= max_chars:\n",
    "            buf = (buf + \" \" + s).strip()\n",
    "        else:\n",
    "            if buf:\n",
    "                chunks.append(buf)\n",
    "            # overlap\n",
    "            if overlap_chars > 0 and chunks:\n",
    "                tail = chunks[-1][-overlap_chars:]\n",
    "                buf = (tail + \" \" + s).strip()\n",
    "            else:\n",
    "                buf = s\n",
    "    if buf:\n",
    "        chunks.append(buf)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c277b68a",
   "metadata": {},
   "source": [
    "ทดสอบ text utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fc2a73d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize: สวัสดีมากๆ!เลย จ้า\n",
      "tokenize: ['สวัสดี', 'มาก', 'ๆ', '!', 'เลย', '    ', 'จ้า', 'าาา']\n",
      "split: ['สวัสดีมากๆ!เลย    จ้าาาา']\n",
      "norm+token: ['สวัสดี', 'มาก', 'ๆ', '!', 'เลย', ' ', 'จ้า']\n",
      "chunk_by_sentences: ['สวัสดีมากๆ!เลย จ้า']\n"
     ]
    }
   ],
   "source": [
    "# test_thai_word = \"กรุงเทพฯ 5 มี.ค. - ธนาคารแห่งประเทศไทย (ธปท.) \\nเตือนประชาชนระวังมิจฉาชีพแอบอ้างเป็นเจ้าหน้าที่ธนาคารหรือหน่วยงานรัฐ ส่ง SMS หรือ LINE ที่มีลิงก์ปลอม เพื่อหลอกให้โอนเงินหรือติดตั้งแอปพลิเคชันอันตราย พร้อมแนะวิธีป้องกันตัวเองจากมิจฉาชีพ\"\n",
    "test_thai_word = \"สวัสดีมากๆ!เลย    จ้าาาา\"\n",
    "print(\"normalize:\",th_normalize(test_thai_word) )\n",
    "print(\"tokenize:\",th_tokenize(test_thai_word))\n",
    "print(\"split:\",sent_split_th(test_thai_word))\n",
    "print(\"norm+token:\",th_tokenize(th_normalize(test_thai_word)))\n",
    "print(\"chunk_by_sentences:\",chunk_by_sentences(test_thai_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d5074",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "ตัวอย่างนี้ใช้ intfloat/multilingual-e5-base หรือ BAAI/beg-m3 รองรับหลายภาษารวมทั้งภาษาไทย ตั้งไว้แบบ CPU เพื่อจะได้ไม่มีปัญหากับเครื่องที่ไม่มีการ์ดจอหรือไม่ได้ตั้งค่าไว้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "07997cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embed_model = SentenceTransformer(\"intfloat/multilingual-e5-base\",device='cpu')\n",
    "embed_model = SentenceTransformer(\"BAAI/bge-m3\",device=device)\n",
    "def embed(texts):\n",
    "    return embed_model.encode([f\"{t}\" for t in texts], normalize_embeddings=True,device=device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d4f854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunk_records(docs):\n",
    "    # สร้างชิ้นข้อมูล (chunks)\n",
    "    chunk_records = []\n",
    "    for d in docs:\n",
    "        chunks = chunk_by_sentences(d[\"description\"], max_chars=500, overlap_chars=50)\n",
    "        for i, c in enumerate(chunks):\n",
    "            chunk_records.append({\n",
    "                \"doc_id\": d[\"id\"],\n",
    "                \"title\": d[\"name\"],\n",
    "                \"chunk_id\": f'{d[\"id\"]}-{i}',\n",
    "                \"text\": c,\n",
    "            })\n",
    "    return chunk_records\n",
    "def create_embedding(chunk_records):\n",
    "    emb_matrix = embed([f\"{r[\"title\"]}:\\n{r[\"text\"]}\"  for r in chunk_records]).astype(\"float32\")\n",
    "    # ดัชนีเวคเตอร์ FAISS\n",
    "    d = emb_matrix.shape[1]\n",
    "    index = faiss.IndexFlatIP(d)  # ใช้ cosine-sim กับเวคเตอร์ normalized = dot product\n",
    "    index.add(emb_matrix)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521430fe",
   "metadata": {},
   "source": [
    "## Indexing Data\n",
    "โหลดข้อมูลจากไฟล์แล้วสร้าง  bm25, vector และ รายการข้อมูล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d481829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_data(file_path):\n",
    "    docs=[]\n",
    "    with open(file_path) as f:\n",
    "        docs = json.load(f)\n",
    "    chunk_records = create_chunk_records(docs)\n",
    "    embedding_index = create_embedding(chunk_records)\n",
    "    bm25_corpus_tokens = [th_tokenize(r[\"text\"]) for r in chunk_records]\n",
    "    bm25_index = BM25Okapi(bm25_corpus_tokens)\n",
    "    return embedding_index, bm25_index, chunk_records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d697b7fd",
   "metadata": {},
   "source": [
    "ทดสอบการโหลดข้อมูล แล้วทำการค้นหาแบบ Full Text(BM25) และ Similar(Vector) พร้อมแสดงคะแนน \n",
    "- data1.json (ภาษาอังกฤษ) ค้นคำว่า \"Thai\" ผลค่อนข้างใกล้เคียงกัน แต่ถ้าใช้ \"ไทย\" BM25 จะได้ score 0 ส่วน vector ถูกบางตัว\n",
    "- data2.json (ภาษาไทย) ค้นคำว่า \"มิจฉาชีพ\" ผลค่อนข้างใกล้เคียงกัน ถ้าใช้ \"Phishing\" BM25 จะได้ score 0 ส่วน Vector ให้ผลดีกว่า"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "14d7292b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25: ['1.5881503124135494:การใช้งาน ATM', '1.2412011622247787:คำเตือนภัยหลอกลวง', '0.0:ทำอย่างไรเพื่อหลีกเลี่ยง Spyware']\n",
      "Vector: ['0.49123451113700867:คำเตือนภัยหลอกลวง', '0.46242836117744446:การใช้งาน ATM', '0.44394198060035706:ระวัง SMS/ลิงก์ปลอม']\n"
     ]
    }
   ],
   "source": [
    "## Test search from index\n",
    "embeded_index,b25_index,chunks_docs = reload_data(\"./data2.json\")# reload index\n",
    "# print(json.dumps(chunks_docs, indent=2)) \n",
    "q_norm = th_normalize(\"มิจฉาชีพ\") # normalize Query\n",
    "\n",
    "# Full Text Search with socre\n",
    "q_tokens = th_tokenize(q_norm) # normalize and tokenize query\n",
    "bm25_scores = b25_index.get_scores(q_tokens)\n",
    "bm25_top_idx = np.argsort(bm25_scores)[::-1][:3]\n",
    "# print([i['title'] for i in b25_index.get_top_n(q_tokens, chunks_docs, n=3)])\n",
    "print(\"BM25:\",[f\"{bm25_scores[i]}:{chunks_docs[i]['title']}\" for i in bm25_top_idx])\n",
    "\n",
    "# Similar search with score\n",
    "q_emb = embed_model.encode([f\"query: {q_norm}\"], normalize_embeddings=True).astype(\"float32\")\n",
    "sim, idx = embeded_index.search(q_emb, 3)  # cosine-sim (dot)\n",
    "print(\"Vector:\",[f\"{i2}:{chunks_docs[i1]['title']}\" for i1,i2 in zip(idx[0],sim[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a91d38",
   "metadata": {},
   "source": [
    "## Hybrid Search\n",
    "รวมการค้นหาสองแบบเข้าด้วยกัน ถ่วงน้ำหนักด้วย alpha การค้นหาแบบ Similar (Vector) อาจจะไม่ค่อยแม่นยำนักกับภาษาไทยที่ค่อนข้างซับซ้อน จะใช้การค้นหาแบบ Full Text(BM25) ร่วมด้วย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4ac91d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query,vector_index,bm25_index,chunk_records, top_k=6, alpha=0.5):\n",
    "    \"\"\"\n",
    "    ค้นหาแบบ BM25 และ vector ถ่วงน้ำหนักด้วย alpha: ถ้า 1.0 เน้น vector ล้วน, ถ้า 0.0 เน้น BM25 ล้วน\n",
    "    \"\"\"\n",
    "    # Vector\n",
    "    q_norm = th_normalize(query)\n",
    "    q_emb = embed_model.encode([f\"query: {q_norm}\"], normalize_embeddings=True).astype(\"float32\")\n",
    "    sim, idx = vector_index.search(q_emb, top_k*3)  # cosine-sim (dot)\n",
    "    vec_scores = np.zeros(len(chunk_records))\n",
    "    vec_scores[idx[0]] = sim[0]\n",
    "    #BM25\n",
    "    q_tokens = th_tokenize(q_norm)\n",
    "    bm25_scores = bm25_index.get_scores(q_tokens)\n",
    "    bm25_top_idx = np.argsort(bm25_scores)[::-1][:top_k*3]  # ขยายเผื่อรวมกับเวคเตอร์\n",
    "\n",
    "    # รวมคะแนน (normalize แบบ min-max)\n",
    "    def norm(x):\n",
    "        x = np.array(x, dtype=np.float32)\n",
    "        if x.max() - x.min() < 1e-8:\n",
    "            return np.zeros_like(x)\n",
    "        return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "    bm25_mask = np.zeros(len(chunk_records)); bm25_mask[bm25_top_idx] = 1\n",
    "    union_idx = np.where((bm25_mask + (vec_scores>0))>0)[0]\n",
    "\n",
    "    score_b = norm(bm25_scores[union_idx])\n",
    "    score_v = norm(vec_scores[union_idx])\n",
    "    score = alpha*score_v + (1-alpha)*score_b\n",
    "\n",
    "    order = union_idx[np.argsort(score)[::-1][:top_k]]\n",
    "    results = []\n",
    "    for i in order:\n",
    "        r = chunk_records[i]\n",
    "        results.append({\n",
    "            \"chunk_id\": r[\"chunk_id\"],\n",
    "            \"doc_id\": r[\"doc_id\"],\n",
    "            \"title\": r[\"title\"],\n",
    "            \"text\": r[\"text\"],\n",
    "            \"score\": float(score[np.where(union_idx==i)][0]),\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c70f28f",
   "metadata": {},
   "source": [
    "## Generate\n",
    "เมื่อนำผลจาก hybrid_search ที่อาจจะผิดพลาดบ้าง มาสร้าง prompt เพื่อประมวลต่อด้วย LLM จะได้คำตอบที่ตรงกับที่ต้องการมากขึ้น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e51789cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# สร้างคำตอบโดยยึดตามหลัก \"ใช้เฉพาะจากบริบท\" ใช้ contexts เหมือนจะดีกว่า context_text\n",
    "def generate_response(query, contexts,max_ctx_chars=1200):\n",
    "    \"\"\"Generate a response using Gemini based on the query and retrieved context\"\"\"\n",
    "    context_text = \"\"\n",
    "    for c in contexts:\n",
    "        if len(context_text) + len(c[\"text\"]) + 2 <= max_ctx_chars:\n",
    "            context_text += f\"- {c['text']}\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful assistant .\n",
    "If the query asks for something not in the provided information, politely indicate \n",
    "that you don't have that specific information but suggest the closest alternatives.\n",
    "Please provide a helpful response that directly answers the user's query based on information below.\n",
    "\n",
    "USER QUERY: {query}\n",
    "\n",
    "INFORMATION:\n",
    "{contexts}\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.5-flash',\n",
    "        contents=prompt,\n",
    "    )\n",
    "    answer = response.text\n",
    "    return prompt, answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a65d19",
   "metadata": {},
   "source": [
    "Reload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "62debe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_index,b25_index,chunks_docs = reload_data(\"./data1.json\")# reload index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9064df",
   "metadata": {},
   "source": [
    "data2.json : doc9 ถูก Chunking ออกมาได้ไม่ดีซักเท่าไหร่"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e2eeb232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_id': '001',\n",
       "  'title': 'La Dotta',\n",
       "  'chunk_id': '001-0',\n",
       "  'text': 'Authentic Italian restaurant specializing in handmade pasta dishes using imported ingredients from Italy. Located in Thonglor district of Bangkok.'},\n",
       " {'doc_id': '002',\n",
       "  'title': 'Peppina',\n",
       "  'chunk_id': '002-0',\n",
       "  'text': 'Neapolitan pizza restaurant with wood-fired ovens imported from Italy. Features traditional Italian dishes and a wide selection of Italian wines.'},\n",
       " {'doc_id': '003',\n",
       "  'title': \"L'Oliva\",\n",
       "  'chunk_id': '003-0',\n",
       "  'text': 'High-end Italian dining with focus on Northern Italian cuisine. Offers homemade pasta, risotto, and seafood specialties in the heart of Sukhumvit.'},\n",
       " {'doc_id': '004',\n",
       "  'title': 'Appia',\n",
       "  'chunk_id': '004-0',\n",
       "  'text': 'Roman-inspired trattoria serving hearty Italian comfort food including porchetta and homemade pasta in a rustic setting in Sukhumvit Soi 31.'},\n",
       " {'doc_id': '005',\n",
       "  'title': 'Pizza Massilia',\n",
       "  'chunk_id': '005-0',\n",
       "  'text': 'Upscale Italian restaurant specializing in gourmet pizzas with premium imported ingredients and authentic Italian recipes with a modern twist.'},\n",
       " {'doc_id': '006',\n",
       "  'title': \"Gianni's\",\n",
       "  'chunk_id': '006-0',\n",
       "  'text': 'Classic Italian restaurant in Sukhumvit offering traditional dishes from various regions of Italy, with an extensive wine collection.'},\n",
       " {'doc_id': '007',\n",
       "  'title': 'Som Tam Nua',\n",
       "  'chunk_id': '007-0',\n",
       "  'text': 'Popular Thai restaurant specializing in Northeastern Thai cuisine, especially spicy papaya salad and grilled chicken. Located in Siam Square.'},\n",
       " {'doc_id': '008',\n",
       "  'title': 'Pad Thai Ekkamai',\n",
       "  'chunk_id': '008-0',\n",
       "  'text': 'Local favorite serving authentic pad thai and other traditional Thai noodle dishes in the trendy Ekkamai neighborhood.'},\n",
       " {'doc_id': '009',\n",
       "  'title': 'Isaan Der',\n",
       "  'chunk_id': '009-0',\n",
       "  'text': 'Northeastern Thai cuisine featuring grilled meats, sticky rice, and spicy salads served in a casual atmosphere near Asok.'},\n",
       " {'doc_id': '010',\n",
       "  'title': 'Gaggan',\n",
       "  'chunk_id': '010-0',\n",
       "  'text': 'Progressive Indian restaurant offering innovative tasting menus with modern techniques while maintaining authentic flavors. Located in Lumpini.'}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2db8616",
   "metadata": {},
   "source": [
    "RAGS ลองปรับ user_query และ alpha ว่าผลแตกต่างกันหรือไม่"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a446b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Search Top Hits: \n",
      "1 Isaan Der (1.000)\n",
      "Northeastern Thai cuisine featuring grilled meats, sticky rice, and spicy salads served in a casual atmosphere near Asok...\n",
      "2 Pad Thai Ekkamai (1.000)\n",
      "Local favorite serving authentic pad thai and other traditional Thai noodle dishes in the trendy Ekkamai neighborhood....\n",
      "3 Appia (1.000)\n",
      "Roman-inspired trattoria serving hearty Italian comfort food including porchetta and homemade pasta in a rustic setting ...\n",
      "4 Som Tam Nua (1.000)\n",
      "Popular Thai restaurant specializing in Northeastern Thai cuisine, especially spicy papaya salad and grilled chicken. Lo...\n",
      "5 Gianni's (1.000)\n",
      "Classic Italian restaurant in Sukhumvit offering traditional dishes from various regions of Italy, with an extensive win...\n",
      "6 Pizza Massilia (1.000)\n",
      "Upscale Italian restaurant specializing in gourmet pizzas with premium imported ingredients and authentic Italian recipe...\n"
     ]
    }
   ],
   "source": [
    "# user_query = \"ถ้าโอนเงินผิดบัญชีควรทำอย่างไร และควรระวังมิจฉาชีพแบบไหน?\"\n",
    "user_query = \"ร้านไหนบ้างขายอาหารไทยหรืออิตาลี\"\n",
    "# user_query = \"ถ้าได้ SMS น่าสงสัยควรทำอย่างไร\"\n",
    "results = hybrid_search(user_query,embeded_index,b25_index,chunks_docs, top_k=6, alpha=1.0)\n",
    "# chunks_docs มีข้อมูลไม่ครบทั้งหมดเช่นที่อยู่ของร้านอาหาร น่าจะเพิ่มเข้าไปด้วยตอนทำ RAG จะได้มีข้อมูลส่วนนี้ด้วย\n",
    "prompt, answer = generate_response(user_query, results)\n",
    "print(\"Hybrid Search Top Hits: \")\n",
    "for i, r in enumerate(results):\n",
    "    print(f\"{i+1} {r['title']} ({r['score']:.3f})\")\n",
    "    print(f\"{r['text'][:120]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2a8af66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      " \n",
      "You are a helpful assistant .\n",
      "If the query asks for something not in the provided information, politely indicate \n",
      "that you don't have that specific information but suggest the closest alternatives.\n",
      "Please provide a helpful response that directly answers the user's query based on information below.\n",
      "\n",
      "USER QUERY: ร้านไหนบ้างขายอาหารไทยหรืออิตาลี\n",
      "\n",
      "INFORMATION:\n",
      "[{'chunk_id': '009-0', 'doc_id': '009', 'title': 'Isaan Der', 'text': 'Northeastern Thai cuisine featuring grilled meats, sticky rice, and spicy salads served in a casual atmosphere near Asok.', 'score': 1.0}, {'chunk_id': '008-0', 'doc_id': '008', 'title': 'Pad Thai Ekkamai', 'text': 'Local favorite serving authentic pad thai and other traditional Thai noodle dishes in the trendy Ekkamai neighborhood.', 'score': 1.0}, {'chunk_id': '004-0', 'doc_id': '004', 'title': 'Appia', 'text': 'Roman-inspired trattoria serving hearty Italian comfort food including porchetta and homemade pasta in a rustic setting in Sukhumvit Soi 31.', 'score': 1.0}, {'chunk_id': '007-0', 'doc_id': '007', 'title': 'Som Tam Nua', 'text': 'Popular Thai restaurant specializing in Northeastern Thai cuisine, especially spicy papaya salad and grilled chicken. Located in Siam Square.', 'score': 1.0}, {'chunk_id': '006-0', 'doc_id': '006', 'title': \"Gianni's\", 'text': 'Classic Italian restaurant in Sukhumvit offering traditional dishes from various regions of Italy, with an extensive wine collection.', 'score': 1.0}, {'chunk_id': '005-0', 'doc_id': '005', 'title': 'Pizza Massilia', 'text': 'Upscale Italian restaurant specializing in gourmet pizzas with premium imported ingredients and authentic Italian recipes with a modern twist.', 'score': 1.0}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Prompt:\\n\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "94135495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ถาม: ร้านไหนบ้างขายอาหารไทยหรืออิตาลี \n",
      " ตอบ:\n",
      " ร้านอาหารที่ขายอาหารไทยหรืออิตาลีตามข้อมูลที่มี ได้แก่:\n",
      "\n",
      "**อาหารไทย:**\n",
      "*   **Isaan Der** (อาหารไทยอีสาน)\n",
      "*   **Pad Thai Ekkamai** (ผัดไทยและอาหารเส้นไทยดั้งเดิม)\n",
      "*   **Som Tam Nua** (อาหารไทยอีสาน เน้นส้มตำและไก่ย่าง)\n",
      "\n",
      "**อาหารอิตาลี:**\n",
      "*   **Appia** (อาหารอิตาเลียนสไตล์โรมัน)\n",
      "*   **Gianni's** (อาหารอิตาเลียนคลาสสิก)\n",
      "*   **Pizza Massilia** (พิซซ่าอิตาเลียนรสเลิศ)\n"
     ]
    }
   ],
   "source": [
    "print(\"ถาม:\",user_query,\"\\n ตอบ:\\n\",answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd20a8f",
   "metadata": {},
   "source": [
    "## สรุป\n",
    "- BM25 จะเหมาะกับข้อมูลที่มีคำในภาษานั้นๆตรงๆ ซึ่งการค้นหาส่วนใหญ่มักเป็นแบบนั้น\n",
    "- Vector เข้าใจคำที่มีความหมายคล้ายกันหรือคนละภาษาได้ เหมาะเวลาที่เราไม่รู้คำที่ชัดเจน\n",
    "- Hybrid Search นำข้อดีของ BM25 และ Vector มาใช้ร่วมกันทำให้มีโอกาสค้นหารูปแบบต่างๆได้\n",
    "- RAGS Hybrid เพิ่มความแม่นยำในการค้นหามากขึ้น"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_pdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
